data_science:
  loss_func: CrossEntropyLoss
  n_qubits: ${n_qubits}
  n_qubits_range_quant: ${n_qubits_range_quant}
  n_layers: ${n_layers}
  n_layers_range_quant: ${n_layers_range_quant}
  epochs: 3
  optimizer:
    # combined:
    #   name: SGD
    #   lr: 0.03
    classical:
      name: SGD
      lr: 0.03
    quantum:
      name: Adam
      lr: 0.04
  optimizer_range:
    # combined:
    #   name: [SGD, Adam, NGD]
    #   lr: [0.01, 0.1, 'log']
    classical:
      name: [SGD, Adam, NGD]
      lr: [0.01, 0.1, 'log']
    quantum:
      name: [SGD, Adam, NGD, QNG] #SPSA
      lr: [0.01, 0.1, 'log']
  TEST_SIZE: ${TEST_SIZE}
  TRAINING_SIZE: ${TRAINING_SIZE}
  classes: ${classes}
  

  # Optuna
  n_trials: 20
  timeout: 10800 #30h
  optuna_path: "studies/split_optimizer.db"
  optuna_sampler_seed:  # should be None, if n_jobs=1 and separate processes are triggered from console
  selective_optimization: False # if true, only optimize classical params
  resume_study: True
  n_jobs: 1
  run_id: "OptunaOptimization#001"

  pool_process: False # alternative pool processing
  pruner_startup_trials: 10
  pruner_warmup_steps: 5
  pruner_interval_steps: 1
  pruner_min_trials: 10
